# ğŸ“Œ Assignment 3: Probabilistic Models & Decision Trees

## ğŸ‘¥ Team Members & Responsibilities

### ğŸ”¹ Part A â€” Gaussian Generative Classifier  
**Assigned to:** **Ahmed Gamal**

**Responsibilities:**
- Load and preprocess the digits dataset  
- Apply stratified 70/15/15 split  
- Standardize features  
- Implement Gaussian Generative Classifier:  
  - Class priors Ï€â‚–  
  - Class means Î¼â‚–  
  - Shared covariance Î£  
  - Regularized covariance Î£â‚— = Î£ + Î»I  
- Tune the hyperparameter Î»  
- Evaluate final model (accuracy, macro precision, recall, F1, confusion matrix)  
- Write Part A analysis section  

---

### ğŸ”¹ Part B â€” Naive Bayes Classifier  
**Assigned to:** **Mohamed Mostafa**

**Responsibilities:**
- Load and preprocess the Adult Income dataset  
- Use only categorical features  
- Handle missing values as separate categories  
- Encode categories as integers  
- Implement Naive Bayes with Laplace smoothing Î±  
- Tune Î± âˆˆ [0.1, 0.5, 1.0, 2.0, 5.0]  
- Compare with sklearn MultinomialNB  
- Perform feature subset analysis  
- Study predicted probability distributions  
- Write Part B analysis and conclusion  

---

### ğŸ”¹ Part C & D â€” Decision Tree & Random Forest  
**Assigned to:** **Mazen Wael**

#### Part C: Decision Tree (from scratch)
- Load breast cancer dataset  
- Stratified 70/15/15 split  
- Implement decision tree with continuous features:  
  - Entropy impurity  
  - Information gain  
  - Best threshold selection  
- Implement stopping rules:  
  - max_depth  
  - min_samples_split  
  - pure nodes  
- Hyperparameter tuning:  
  - max_depth âˆˆ {2,4,6,8,10}  
  - min_samples_split âˆˆ {2,5,10}  
- Evaluate final model (accuracy, precision, recall, F1, confusion matrix)  
- Analyze feature importance & overfitting  

#### Part D: Random Forest (Bonus)
- Implement Random Forest using your own tree  
- Bootstrap sampling  
- Random subset of features per split  
- Tune:
  - T âˆˆ {5,10,30,50}  
  - max_features âˆˆ {âˆšd, d/2}  
- Final evaluation on test set  
- Compare with Part C (biasâ€“variance analysis)  

---

## ğŸ“ Project Structure
project/
â”‚â”€â”€ partA/ # Gaussian Generative Model (Ahmed)
â”‚â”€â”€ partB/ # Naive Bayes (Mohamed)
â”‚â”€â”€ partC/ # Decision Tree (Mazen)
â”‚â”€â”€ partD/ # Random Forest (Mazen)
â”‚â”€â”€ data/
â”‚â”€â”€ report.pdf
â”‚â”€â”€ README.md


---

âœ”ï¸ Summary

This assignment implements and compares:

Gaussian Generative Classifier

Naive Bayes

Decision Tree

Random Forest (bonus)

Each team member is responsible for a full ML pipeline for their assigned part, including preprocessing, model implementation, hyperparameter tuning, and evaluation.






## ğŸ“ Project Structure
